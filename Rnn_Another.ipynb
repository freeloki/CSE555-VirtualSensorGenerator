{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utils\n",
    "import model_utils\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128)\n"
     ]
    }
   ],
   "source": [
    "data = data_utils.load_training_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN-LSTM\n",
      "<tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f2696a94da0>\n",
      "RNN\n",
      "Tensor(\"rnn_model/rnn/transpose_1:0\", shape=(4, 10, 128), dtype=float32)\n",
      "W1\n",
      "<tf.Variable 'rnn_model/w1:0' shape=(128, 32) dtype=float32_ref>\n",
      "B1\n",
      "<tf.Variable 'rnn_model/b1:0' shape=(32,) dtype=float32_ref>\n",
      "ACTIVATION\n",
      "Tensor(\"rnn_model/Sigmoid:0\", shape=(40, 32), dtype=float32)\n",
      "W2\n",
      "<tf.Variable 'rnn_model/w2:0' shape=(32, 1) dtype=float32_ref>\n",
      "B2\n",
      "<tf.Variable 'rnn_model/b2:0' shape=(1,) dtype=float32_ref>\n",
      "OUTPUT\n",
      "Tensor(\"rnn_model/add_1:0\", shape=(40, 1), dtype=float32)\n",
      "PREDS\n",
      "Tensor(\"rnn_model/Reshape_1:0\", shape=(4, 10, 1), dtype=float32)\n",
      "RNN-LSTM\n",
      "<tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f26974f5748>\n",
      "RNN\n",
      "Tensor(\"rnn_model_1/rnn/transpose_1:0\", shape=(1, 1, 128), dtype=float32)\n",
      "W1\n",
      "<tf.Variable 'rnn_model/w1:0' shape=(128, 32) dtype=float32_ref>\n",
      "B1\n",
      "<tf.Variable 'rnn_model/b1:0' shape=(32,) dtype=float32_ref>\n",
      "ACTIVATION\n",
      "Tensor(\"rnn_model_1/Sigmoid:0\", shape=(1, 32), dtype=float32)\n",
      "W2\n",
      "<tf.Variable 'rnn_model/w2:0' shape=(32, 1) dtype=float32_ref>\n",
      "B2\n",
      "<tf.Variable 'rnn_model/b2:0' shape=(1,) dtype=float32_ref>\n",
      "OUTPUT\n",
      "Tensor(\"rnn_model_1/add_1:0\", shape=(1, 1), dtype=float32)\n",
      "PREDS\n",
      "Tensor(\"rnn_model_1/Reshape_1:0\", shape=(1, 1, 1), dtype=float32)\n",
      "0   0.08911255\n",
      "1   0.057446692\n",
      "2   0.05338617\n",
      "3   0.052827112\n",
      "4   0.051933568\n",
      "5   0.05346409\n",
      "6   0.05175501\n",
      "7   0.051423293\n",
      "8   0.051558435\n",
      "9   0.050097946\n",
      "10   0.05010134\n",
      "11   0.050152898\n",
      "12   0.050482687\n",
      "13   0.049451515\n",
      "14   0.0491771\n",
      "15   0.04901179\n",
      "16   0.048956886\n",
      "17   0.048655655\n",
      "18   0.048376456\n",
      "19   0.047951948\n",
      "20   0.04806431\n",
      "21   0.047525857\n",
      "22   0.047866542\n",
      "23   0.047494877\n",
      "24   0.04697659\n",
      "25   0.046604477\n",
      "26   0.046690077\n",
      "27   0.046476133\n",
      "28   0.046145972\n",
      "29   0.04577828\n",
      "30   0.04528381\n",
      "31   0.0450695\n",
      "32   0.04461009\n",
      "33   0.04420843\n",
      "34   0.04423882\n",
      "35   0.04361978\n",
      "36   0.04285591\n",
      "37   0.042968687\n",
      "38   0.042539608\n",
      "39   0.042531833\n",
      "40   0.041564446\n",
      "41   0.040283006\n",
      "42   0.03996634\n",
      "43   0.039839555\n",
      "44   0.038846638\n",
      "45   0.038332365\n",
      "46   0.037880633\n",
      "47   0.037789084\n",
      "48   0.03656222\n",
      "49   0.035974298\n",
      "50   0.03546126\n",
      "51   0.03543689\n",
      "52   0.03502903\n",
      "53   0.033857998\n",
      "54   0.03461021\n",
      "55   0.033821717\n",
      "56   0.033334386\n",
      "57   0.03267156\n",
      "58   0.031125585\n",
      "59   0.030306358\n",
      "60   0.03026514\n",
      "61   0.030137813\n",
      "62   0.028678972\n",
      "63   0.029049598\n",
      "64   0.028825292\n",
      "65   0.028106835\n",
      "66   0.02677985\n",
      "67   0.025145866\n",
      "68   0.027194204\n",
      "69   0.028295768\n",
      "70   0.02715101\n",
      "71   0.024989147\n",
      "72   0.02560851\n",
      "73   0.024265714\n",
      "74   0.024806976\n",
      "75   0.023687454\n",
      "76   0.023192484\n",
      "77   0.024251318\n",
      "78   0.023239873\n",
      "79   0.02242265\n",
      "80   0.023051066\n",
      "81   0.022706268\n",
      "82   0.021622933\n",
      "83   0.021401176\n",
      "84   0.021070478\n",
      "85   0.021350281\n",
      "86   0.021732131\n",
      "87   0.020574339\n",
      "88   0.021053625\n",
      "89   0.020257445\n",
      "90   0.019655846\n",
      "91   0.018899852\n",
      "92   0.019623779\n",
      "93   0.020297652\n",
      "94   0.019465357\n",
      "95   0.017925704\n",
      "96   0.018823309\n",
      "97   0.018532759\n",
      "98   0.01890971\n",
      "99   0.01847165\n",
      "100   0.017998256\n",
      "101   0.018208211\n",
      "102   0.01860766\n",
      "103   0.018304849\n",
      "104   0.017100278\n",
      "105   0.01777276\n",
      "106   0.016725706\n",
      "107   0.016625594\n",
      "108   0.017015396\n",
      "109   0.016770784\n",
      "110   0.016312784\n",
      "111   0.015922751\n",
      "112   0.016432097\n",
      "113   0.017028842\n",
      "114   0.01560892\n",
      "115   0.016969576\n",
      "116   0.016786184\n",
      "117   0.016378593\n",
      "118   0.0154237095\n",
      "119   0.01574981\n",
      "120   0.015543293\n",
      "121   0.015978886\n",
      "122   0.017176818\n",
      "123   0.014832415\n",
      "124   0.014493441\n",
      "125   0.015827768\n",
      "126   0.016685102\n",
      "127   0.016182534\n",
      "128   0.014459755\n",
      "129   0.014268652\n",
      "130   0.014412675\n",
      "131   0.01451844\n",
      "132   0.015286808\n",
      "133   0.014592765\n",
      "134   0.014167543\n",
      "135   0.014335196\n",
      "136   0.014065483\n",
      "137   0.014932287\n",
      "138   0.014136259\n",
      "139   0.0139745055\n",
      "140   0.013670338\n",
      "141   0.014335201\n",
      "142   0.014463396\n",
      "143   0.013923323\n",
      "144   0.014557158\n",
      "145   0.014269952\n",
      "146   0.014172732\n",
      "147   0.013648769\n",
      "148   0.013543849\n",
      "149   0.013631752\n",
      "150   0.014525892\n",
      "151   0.013916147\n",
      "152   0.014350278\n",
      "153   0.01441904\n",
      "154   0.013039428\n",
      "155   0.012658017\n",
      "156   0.013541311\n",
      "157   0.013226615\n",
      "158   0.013726049\n",
      "159   0.014326283\n",
      "160   0.013227947\n",
      "161   0.012949553\n",
      "162   0.013223934\n",
      "163   0.0130513795\n",
      "164   0.015127417\n",
      "165   0.013925903\n",
      "166   0.0123046655\n",
      "167   0.012192945\n",
      "168   0.0139077725\n",
      "169   0.013422079\n",
      "170   0.01326397\n",
      "171   0.0137194\n",
      "172   0.012514942\n",
      "173   0.013752402\n",
      "174   0.013118143\n",
      "175   0.012772247\n",
      "176   0.013159729\n",
      "177   0.013384431\n",
      "178   0.013132082\n",
      "179   0.013960666\n",
      "180   0.012668891\n",
      "181   0.0126044005\n",
      "182   0.012753351\n",
      "183   0.012913949\n",
      "184   0.013236587\n",
      "185   0.013217939\n",
      "186   0.0126052685\n",
      "187   0.012930965\n",
      "188   0.012981439\n",
      "189   0.012984837\n",
      "190   0.012896312\n",
      "191   0.01273908\n",
      "192   0.01270474\n",
      "193   0.013481257\n",
      "194   0.012568567\n",
      "195   0.012526919\n",
      "196   0.012636862\n",
      "197   0.01253556\n",
      "198   0.012571663\n",
      "199   0.01276441\n",
      "200   0.013105531\n",
      "201   0.012771588\n",
      "202   0.011880884\n",
      "203   0.013131095\n",
      "204   0.013062401\n",
      "205   0.0122127505\n",
      "206   0.011865009\n",
      "207   0.011861777\n",
      "208   0.013064045\n",
      "209   0.0127638355\n",
      "210   0.012217508\n",
      "211   0.012639561\n",
      "212   0.012502387\n",
      "213   0.012099794\n",
      "214   0.01247009\n",
      "215   0.012499661\n",
      "216   0.012360315\n",
      "217   0.012148005\n",
      "218   0.012711116\n",
      "219   0.012462338\n",
      "220   0.012428627\n",
      "221   0.012253056\n",
      "222   0.011419418\n",
      "223   0.012384897\n",
      "224   0.012498414\n",
      "225   0.011607411\n",
      "226   0.011853414\n",
      "227   0.011923984\n",
      "228   0.0125024365\n",
      "229   0.011723748\n",
      "230   0.012025457\n",
      "231   0.012101164\n",
      "232   0.013673604\n",
      "233   0.012684975\n",
      "234   0.011417036\n",
      "235   0.011993147\n",
      "236   0.013471574\n",
      "237   0.012197045\n",
      "238   0.011750136\n",
      "239   0.011996508\n",
      "240   0.012632516\n",
      "241   0.011249199\n",
      "242   0.013049244\n",
      "243   0.012743536\n",
      "244   0.011585179\n",
      "245   0.011219553\n",
      "246   0.011378238\n",
      "247   0.012139818\n",
      "248   0.012142704\n",
      "249   0.0123983165\n",
      "250   0.01252944\n",
      "251   0.012323809\n",
      "252   0.011617851\n",
      "253   0.012182404\n",
      "254   0.011841473\n",
      "255   0.011410334\n",
      "256   0.011098589\n",
      "257   0.011524195\n",
      "258   0.012192495\n",
      "259   0.012395073\n",
      "260   0.011622781\n",
      "261   0.011917566\n",
      "262   0.011760255\n",
      "263   0.012629706\n",
      "264   0.011993484\n",
      "265   0.011690872\n",
      "266   0.012754847\n",
      "267   0.011957337\n",
      "268   0.012768339\n",
      "269   0.011782911\n",
      "270   0.011843246\n",
      "271   0.011290239\n",
      "272   0.011938554\n",
      "273   0.01234478\n",
      "274   0.012165534\n",
      "275   0.011959616\n",
      "276   0.01123469\n",
      "277   0.012545133\n",
      "278   0.011812267\n",
      "279   0.012040904\n",
      "280   0.011793028\n",
      "281   0.010821104\n",
      "282   0.012638851\n",
      "283   0.011897308\n",
      "284   0.012167636\n",
      "285   0.0112579595\n",
      "286   0.011331427\n",
      "287   0.011885429\n",
      "288   0.012573416\n",
      "289   0.011856862\n",
      "290   0.011446362\n",
      "291   0.011255359\n",
      "292   0.012022167\n",
      "293   0.01167138\n",
      "294   0.012243933\n",
      "295   0.011769192\n",
      "296   0.012013201\n",
      "297   0.011006805\n",
      "298   0.011988254\n",
      "299   0.011437221\n",
      "300   0.010450293\n",
      "301   0.011766021\n",
      "302   0.012624078\n",
      "303   0.011701389\n",
      "304   0.011807977\n",
      "305   0.011721039\n",
      "306   0.011077073\n",
      "307   0.012115764\n",
      "308   0.011557988\n",
      "309   0.011804015\n",
      "310   0.011908844\n",
      "311   0.011057626\n",
      "312   0.011562259\n",
      "313   0.011367035\n",
      "314   0.012165773\n",
      "315   0.012135063\n",
      "316   0.011448833\n",
      "317   0.010272764\n",
      "318   0.010824658\n",
      "319   0.011413136\n",
      "320   0.010804323\n",
      "321   0.010337267\n",
      "322   0.010538646\n",
      "323   0.011201452\n",
      "324   0.01073454\n",
      "325   0.010784513\n",
      "326   0.011122773\n",
      "327   0.011123386\n",
      "328   0.010828981\n",
      "329   0.011072126\n",
      "330   0.011074211\n",
      "331   0.011503682\n",
      "332   0.011261551\n",
      "333   0.011075173\n",
      "334   0.011858772\n",
      "335   0.0113682775\n",
      "336   0.011582222\n",
      "337   0.011130812\n",
      "338   0.010765362\n",
      "339   0.011555722\n",
      "340   0.010768752\n",
      "341   0.011009577\n",
      "342   0.0108421985\n",
      "343   0.012018709\n",
      "344   0.011145379\n",
      "345   0.01012509\n",
      "346   0.01114981\n",
      "347   0.010843413\n",
      "348   0.01069785\n",
      "349   0.010947445\n",
      "350   0.011265616\n",
      "351   0.011290574\n",
      "352   0.010627973\n",
      "353   0.012133153\n",
      "354   0.012505471\n",
      "355   0.011018166\n",
      "356   0.010747976\n",
      "357   0.0112185\n",
      "358   0.0107175\n",
      "359   0.010889907\n",
      "360   0.010644821\n",
      "361   0.011066193\n",
      "362   0.010860036\n",
      "363   0.01083117\n",
      "364   0.01081623\n",
      "365   0.010946583\n",
      "366   0.012876194\n",
      "367   0.0114840735\n",
      "368   0.011070496\n",
      "369   0.010629949\n",
      "370   0.011871008\n",
      "371   0.011394057\n",
      "372   0.011548553\n",
      "373   0.010634331\n",
      "374   0.010177574\n",
      "375   0.009801386\n",
      "376   0.010455524\n",
      "377   0.0122836\n",
      "378   0.011062873\n",
      "379   0.011540749\n",
      "380   0.01103353\n",
      "381   0.010783995\n",
      "382   0.00998904\n",
      "383   0.010853695\n",
      "384   0.011568357\n",
      "385   0.011522598\n",
      "386   0.010514833\n",
      "387   0.010866452\n",
      "388   0.010914489\n",
      "389   0.010260766\n",
      "390   0.0110112\n",
      "391   0.011233362\n",
      "392   0.011092897\n",
      "393   0.011423358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394   0.01123518\n",
      "395   0.011934238\n",
      "396   0.011152452\n",
      "397   0.01115005\n",
      "398   0.010173331\n",
      "399   0.011458011\n",
      "400   0.012321941\n",
      "401   0.010647511\n",
      "402   0.010323169\n",
      "403   0.010362287\n",
      "404   0.011681787\n",
      "405   0.01175986\n",
      "406   0.011250104\n",
      "407   0.0100786155\n",
      "408   0.010093643\n",
      "409   0.01099136\n",
      "410   0.0103393\n",
      "411   0.011608144\n",
      "412   0.010975433\n",
      "413   0.010236271\n",
      "414   0.010767472\n",
      "415   0.010231288\n",
      "416   0.0101674935\n",
      "417   0.010338324\n",
      "418   0.009903191\n",
      "419   0.010139468\n",
      "420   0.010818961\n",
      "421   0.010315086\n",
      "422   0.010248639\n",
      "423   0.00951302\n",
      "424   0.010866455\n",
      "425   0.010565665\n",
      "426   0.0105392635\n",
      "427   0.011179816\n",
      "428   0.010587071\n",
      "429   0.010386591\n",
      "430   0.01052838\n",
      "431   0.010057241\n",
      "432   0.010417532\n",
      "433   0.010965414\n",
      "434   0.010473191\n",
      "435   0.011014321\n",
      "436   0.010135356\n",
      "437   0.01055525\n",
      "438   0.009702737\n",
      "439   0.011261452\n",
      "440   0.010659566\n",
      "441   0.010231769\n",
      "442   0.0100155035\n",
      "443   0.011262442\n",
      "444   0.011039566\n",
      "445   0.01090235\n",
      "446   0.010305121\n",
      "447   0.009849716\n",
      "448   0.0118318675\n",
      "449   0.012163349\n",
      "450   0.011069066\n",
      "451   0.010169339\n",
      "452   0.010680476\n",
      "453   0.010040992\n",
      "454   0.0108345095\n",
      "455   0.010927636\n",
      "456   0.010773154\n",
      "457   0.011057401\n",
      "458   0.00986309\n",
      "459   0.009785023\n",
      "460   0.010563372\n",
      "461   0.011102871\n",
      "462   0.010384973\n",
      "463   0.009953487\n",
      "464   0.010038969\n",
      "465   0.010794785\n",
      "466   0.009979113\n",
      "467   0.010366779\n",
      "468   0.010759722\n",
      "469   0.010599249\n",
      "470   0.010986227\n",
      "471   0.011071393\n",
      "472   0.01157879\n",
      "473   0.011184854\n",
      "474   0.010964642\n",
      "475   0.010256506\n",
      "476   0.010554323\n",
      "477   0.009144387\n",
      "478   0.010902104\n",
      "479   0.011000471\n",
      "480   0.010563741\n",
      "481   0.009900787\n",
      "482   0.010024093\n",
      "483   0.010423511\n",
      "484   0.010134747\n",
      "485   0.009840257\n",
      "486   0.011225564\n",
      "487   0.009685047\n",
      "488   0.00981328\n",
      "489   0.009161848\n",
      "490   0.010285329\n",
      "491   0.009470289\n",
      "492   0.010314651\n",
      "493   0.009993024\n",
      "494   0.010661136\n",
      "495   0.010223837\n",
      "496   0.009629727\n",
      "497   0.00989635\n",
      "498   0.009489962\n",
      "499   0.010272737\n",
      "500   0.0101856245\n",
      "501   0.01010879\n",
      "502   0.010946318\n",
      "503   0.0106824795\n",
      "504   0.010459683\n",
      "505   0.010373556\n",
      "506   0.011716074\n",
      "507   0.010078667\n",
      "508   0.011024834\n",
      "509   0.010531958\n",
      "510   0.010038692\n",
      "511   0.009668588\n",
      "512   0.00988485\n",
      "513   0.009585911\n",
      "514   0.009741583\n",
      "515   0.012070896\n",
      "516   0.010573626\n",
      "517   0.010164867\n",
      "518   0.010893881\n",
      "519   0.010233947\n",
      "520   0.009412468\n",
      "521   0.00924659\n",
      "522   0.010470802\n",
      "523   0.009769919\n",
      "524   0.009424877\n",
      "525   0.010069838\n",
      "526   0.009933655\n",
      "527   0.010062592\n",
      "528   0.009496229\n",
      "529   0.00999635\n",
      "530   0.009529865\n",
      "531   0.009521411\n",
      "532   0.010142092\n",
      "533   0.011025142\n",
      "534   0.010265406\n",
      "535   0.01041106\n",
      "536   0.01003194\n",
      "537   0.010332561\n",
      "538   0.00994751\n",
      "539   0.0112558585\n",
      "540   0.011304043\n",
      "541   0.010178108\n",
      "542   0.009429706\n",
      "543   0.009762727\n",
      "544   0.010316752\n",
      "545   0.009557447\n",
      "546   0.01005239\n",
      "547   0.010750976\n",
      "548   0.010552769\n",
      "549   0.010467207\n",
      "550   0.010552973\n",
      "551   0.010124699\n",
      "552   0.009753344\n",
      "553   0.009772751\n",
      "554   0.010218135\n",
      "555   0.010147487\n",
      "556   0.01032102\n",
      "557   0.010606419\n",
      "558   0.010077317\n",
      "559   0.010435632\n",
      "560   0.010445963\n",
      "561   0.009327186\n",
      "562   0.009118185\n",
      "563   0.010047236\n",
      "564   0.009902853\n",
      "565   0.009556903\n",
      "566   0.009311829\n",
      "567   0.009933511\n",
      "568   0.010238687\n",
      "569   0.009844596\n",
      "570   0.010342213\n",
      "571   0.009581784\n",
      "572   0.009192402\n",
      "573   0.008984057\n",
      "574   0.009675688\n",
      "575   0.009610032\n",
      "576   0.010769616\n",
      "577   0.010209533\n",
      "578   0.009053877\n",
      "579   0.010064216\n",
      "580   0.010021382\n",
      "581   0.009815199\n",
      "582   0.009519517\n",
      "583   0.009478019\n",
      "584   0.009011864\n",
      "585   0.009380498\n",
      "586   0.009683922\n",
      "587   0.009642743\n",
      "588   0.009136729\n",
      "589   0.009670678\n",
      "590   0.010378437\n",
      "591   0.009603199\n",
      "592   0.009495324\n",
      "593   0.009715087\n",
      "594   0.0090191\n",
      "595   0.010704696\n",
      "596   0.010422276\n",
      "597   0.009500532\n",
      "598   0.00976738\n",
      "599   0.01093024\n",
      "600   0.009688219\n",
      "601   0.009603957\n",
      "602   0.010675794\n",
      "603   0.011245517\n",
      "604   0.010631597\n",
      "605   0.009535173\n",
      "606   0.009787494\n",
      "607   0.009711058\n",
      "608   0.009925126\n",
      "609   0.010025601\n",
      "610   0.010001809\n",
      "611   0.009198527\n",
      "612   0.009882347\n",
      "613   0.010159303\n",
      "614   0.010420018\n",
      "615   0.009954856\n",
      "616   0.010484044\n",
      "617   0.009722262\n",
      "618   0.0091337\n",
      "619   0.009393888\n",
      "620   0.010350113\n",
      "621   0.0096939085\n",
      "622   0.010658384\n",
      "623   0.009668244\n",
      "624   0.009167634\n",
      "625   0.009619377\n",
      "626   0.009760571\n",
      "627   0.01142438\n",
      "628   0.010382345\n",
      "629   0.010001751\n",
      "630   0.008660052\n",
      "631   0.009570647\n",
      "632   0.00973336\n",
      "633   0.010664726\n",
      "634   0.010372291\n",
      "635   0.0087584965\n",
      "636   0.008599583\n",
      "637   0.009278658\n",
      "638   0.00989347\n",
      "639   0.009627788\n",
      "640   0.009004306\n",
      "641   0.0101148\n",
      "642   0.00966069\n",
      "643   0.009827156\n",
      "644   0.009591788\n",
      "645   0.008988337\n",
      "646   0.008874384\n",
      "647   0.008999055\n",
      "648   0.009299206\n",
      "649   0.00919999\n",
      "650   0.009504458\n",
      "651   0.00919707\n",
      "652   0.009900036\n",
      "653   0.010012794\n",
      "654   0.010808234\n",
      "655   0.009398414\n",
      "656   0.009243496\n",
      "657   0.009732057\n",
      "658   0.010799731\n",
      "659   0.009656369\n",
      "660   0.00919621\n",
      "661   0.009336421\n",
      "662   0.009974461\n",
      "663   0.009584796\n",
      "664   0.009909296\n",
      "665   0.010191369\n",
      "666   0.01010996\n",
      "667   0.010263326\n",
      "668   0.009689428\n",
      "669   0.009388362\n",
      "670   0.01039918\n",
      "671   0.009709472\n",
      "672   0.009507967\n",
      "673   0.010420907\n",
      "674   0.010935091\n",
      "675   0.009284232\n",
      "676   0.009814092\n",
      "677   0.0094460985\n",
      "678   0.009324338\n",
      "679   0.009417223\n",
      "680   0.00960429\n",
      "681   0.009117439\n",
      "682   0.009483733\n",
      "683   0.008943341\n",
      "684   0.0084268255\n",
      "685   0.00951715\n",
      "686   0.009979225\n",
      "687   0.0104130525\n",
      "688   0.010001316\n",
      "689   0.009185533\n",
      "690   0.009153758\n",
      "691   0.008338499\n",
      "692   0.008100358\n",
      "693   0.009114814\n",
      "694   0.009169407\n",
      "695   0.009405227\n",
      "696   0.009116581\n",
      "697   0.0092135435\n",
      "698   0.008650094\n",
      "699   0.009694903\n",
      "700   0.009316914\n",
      "701   0.008970462\n",
      "702   0.010287639\n",
      "703   0.009036434\n",
      "704   0.008992326\n",
      "705   0.009751758\n",
      "706   0.009225203\n",
      "707   0.008922776\n",
      "708   0.009663504\n",
      "709   0.01010801\n",
      "710   0.009737511\n",
      "711   0.009367056\n",
      "712   0.009157038\n",
      "713   0.010037683\n",
      "714   0.010816053\n",
      "715   0.009781376\n",
      "716   0.00983304\n",
      "717   0.0093357405\n",
      "718   0.009941983\n",
      "719   0.009693967\n",
      "720   0.009490482\n",
      "721   0.009568238\n",
      "722   0.009541431\n",
      "723   0.009039149\n",
      "724   0.010123206\n",
      "725   0.010519081\n",
      "726   0.00945999\n",
      "727   0.009226225\n",
      "728   0.00958356\n",
      "729   0.010240026\n",
      "730   0.00982796\n",
      "731   0.009133173\n",
      "732   0.010118749\n",
      "733   0.009150759\n",
      "734   0.010398367\n",
      "735   0.009971406\n",
      "736   0.010342248\n",
      "737   0.012124049\n",
      "738   0.0104389405\n",
      "739   0.009570967\n",
      "740   0.008819558\n",
      "741   0.008384557\n",
      "742   0.009832768\n",
      "743   0.011812477\n",
      "744   0.010471774\n",
      "745   0.008918231\n",
      "746   0.00975689\n",
      "747   0.008597529\n",
      "748   0.009176405\n",
      "749   0.009308926\n",
      "750   0.009227915\n",
      "751   0.009018882\n",
      "752   0.009572894\n",
      "753   0.010141132\n",
      "754   0.009448948\n",
      "755   0.009079287\n",
      "756   0.009291829\n",
      "757   0.009916839\n",
      "758   0.008458401\n",
      "759   0.009438349\n",
      "760   0.008805593\n",
      "761   0.0084394105\n",
      "762   0.009287767\n",
      "763   0.009033916\n",
      "764   0.009373568\n",
      "765   0.0086337505\n",
      "766   0.008246613\n",
      "767   0.00872394\n",
      "768   0.008550583\n",
      "769   0.007857665\n",
      "770   0.00990494\n",
      "771   0.009820914\n",
      "772   0.009285059\n",
      "773   0.009704801\n",
      "774   0.010189112\n",
      "775   0.008790077\n",
      "776   0.008962127\n",
      "777   0.008893205\n",
      "778   0.009522659\n",
      "779   0.009204343\n",
      "780   0.008931616\n",
      "781   0.009286125\n",
      "782   0.008977801\n",
      "783   0.008763029\n",
      "784   0.00901602\n",
      "785   0.009121965\n",
      "786   0.008159998\n",
      "787   0.008032746\n",
      "788   0.008542239\n",
      "789   0.008562049\n",
      "790   0.008647237\n",
      "791   0.008572071\n",
      "792   0.009280342\n",
      "793   0.00818617\n",
      "794   0.008145126\n",
      "795   0.008248756\n",
      "796   0.008688497\n",
      "797   0.0086547155\n",
      "798   0.008090471\n",
      "799   0.008272971\n",
      "800   0.008996723\n",
      "801   0.0075598676\n",
      "802   0.0087655\n",
      "803   0.0099481465\n",
      "804   0.008948444\n",
      "805   0.009004088\n",
      "806   0.008783884\n",
      "807   0.009175623\n",
      "808   0.008047158\n",
      "809   0.008066372\n",
      "810   0.007890362\n",
      "811   0.008435014\n",
      "812   0.008736838\n",
      "813   0.009032125\n",
      "814   0.00890181\n",
      "815   0.009110279\n",
      "816   0.008803792\n",
      "817   0.008060861\n",
      "818   0.009273079\n",
      "819   0.009093542\n",
      "820   0.008995433\n",
      "821   0.008274774\n",
      "822   0.007461818\n",
      "823   0.00970635\n",
      "824   0.009465392\n",
      "825   0.0092913695\n",
      "826   0.008649114\n",
      "827   0.007941388\n",
      "828   0.009143282\n",
      "829   0.00988801\n",
      "830   0.009161097\n",
      "831   0.00946175\n",
      "832   0.009273287\n",
      "833   0.008001291\n",
      "834   0.0081974715\n",
      "835   0.0073092966\n",
      "836   0.0076260166\n",
      "837   0.008354035\n",
      "838   0.008794977\n",
      "839   0.008667348\n",
      "840   0.008106442\n",
      "841   0.008246668\n",
      "842   0.00837504\n",
      "843   0.009200166\n",
      "844   0.008062473\n",
      "845   0.008851403\n",
      "846   0.007869068\n",
      "847   0.0074633462\n",
      "848   0.008647121\n",
      "849   0.009303116\n",
      "850   0.009427727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851   0.009361988\n",
      "852   0.00762607\n",
      "853   0.007936366\n",
      "854   0.009184244\n",
      "855   0.008503964\n",
      "856   0.00858117\n",
      "857   0.00854447\n",
      "858   0.007625374\n",
      "859   0.009034138\n",
      "860   0.010612236\n",
      "861   0.009197895\n",
      "862   0.007839236\n",
      "863   0.008030099\n",
      "864   0.0077084783\n",
      "865   0.008559564\n",
      "866   0.009555456\n",
      "867   0.009815824\n",
      "868   0.008609752\n",
      "869   0.009020131\n",
      "870   0.0089929355\n",
      "871   0.008745912\n",
      "872   0.008986984\n",
      "873   0.010007348\n",
      "874   0.009731564\n",
      "875   0.010065481\n",
      "876   0.009532076\n",
      "877   0.010636052\n",
      "878   0.009235466\n",
      "879   0.008379227\n",
      "880   0.0109031405\n",
      "881   0.010431202\n",
      "882   0.009283114\n",
      "883   0.009313927\n",
      "884   0.009429736\n",
      "885   0.00882053\n",
      "886   0.0080667\n",
      "887   0.008902417\n",
      "888   0.009188808\n",
      "889   0.009236808\n",
      "890   0.007895233\n",
      "891   0.008272586\n",
      "892   0.008915749\n",
      "893   0.008547252\n",
      "894   0.009041713\n",
      "895   0.008533221\n",
      "896   0.009624302\n",
      "897   0.010332193\n",
      "898   0.008531687\n",
      "899   0.009488456\n",
      "900   0.009262478\n",
      "901   0.009003074\n",
      "902   0.0091143865\n",
      "903   0.009509964\n",
      "904   0.010487865\n",
      "905   0.009954206\n",
      "906   0.00946788\n",
      "907   0.009781704\n",
      "908   0.009058394\n",
      "909   0.01005437\n",
      "910   0.009407699\n",
      "911   0.01070949\n",
      "912   0.011930752\n",
      "913   0.011143028\n",
      "914   0.009827537\n",
      "915   0.0096777575\n",
      "916   0.0088224495\n",
      "917   0.009680211\n",
      "918   0.010524663\n",
      "919   0.011073594\n",
      "920   0.009342236\n",
      "921   0.00887256\n",
      "922   0.009556552\n",
      "923   0.011617536\n",
      "924   0.011176248\n",
      "925   0.01066255\n",
      "926   0.009372464\n",
      "927   0.009550024\n",
      "928   0.0091213845\n",
      "929   0.008645613\n",
      "930   0.010734042\n",
      "931   0.01042259\n",
      "932   0.009551533\n",
      "933   0.010468151\n",
      "934   0.009136044\n",
      "935   0.01141324\n",
      "936   0.010152649\n",
      "937   0.0094347885\n",
      "938   0.008707105\n",
      "939   0.010954316\n",
      "940   0.00976613\n",
      "941   0.00958967\n",
      "942   0.010493002\n",
      "943   0.009745131\n",
      "944   0.0090193385\n",
      "945   0.008957489\n",
      "946   0.009087425\n",
      "947   0.009307865\n",
      "948   0.009123387\n",
      "949   0.009895333\n",
      "950   0.011011169\n",
      "951   0.009887198\n",
      "952   0.008981512\n",
      "953   0.009629608\n",
      "954   0.0108843325\n",
      "955   0.009305703\n",
      "956   0.010387678\n",
      "957   0.010781135\n",
      "958   0.009663104\n",
      "959   0.009801686\n",
      "960   0.009128363\n",
      "961   0.009526064\n",
      "962   0.009380024\n",
      "963   0.009391258\n",
      "964   0.010273603\n",
      "965   0.00991823\n",
      "966   0.009054402\n",
      "967   0.009541932\n",
      "968   0.009323707\n",
      "969   0.012316786\n",
      "970   0.010476058\n",
      "971   0.009975122\n",
      "972   0.009163026\n",
      "973   0.009080938\n",
      "974   0.009309498\n",
      "975   0.009580284\n",
      "976   0.009881178\n",
      "977   0.009790575\n",
      "978   0.0104876915\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f7a4be51974d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_for_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DevOps/MASTER/CSE555-VirtualSensorGenerator/model.py\u001b[0m in \u001b[0;36mtrain_for_epoch\u001b[0;34m(self, sess, data_loader)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 feed_dict={\n\u001b[1;32m    104\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_holder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_holder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcur_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 })\n",
      "\u001b[0;32m~/DevOps/VirtualEnvs/deepEnv-GPU/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DevOps/VirtualEnvs/deepEnv-GPU/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DevOps/VirtualEnvs/deepEnv-GPU/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DevOps/VirtualEnvs/deepEnv-GPU/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DevOps/VirtualEnvs/deepEnv-GPU/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DevOps/VirtualEnvs/deepEnv-GPU/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "\n",
    "model_utils.reset_session_and_model()\n",
    "with tf.Session() as sess:\n",
    "    train_config = model.ModelConfig()\n",
    "    test_config = model.ModelConfig()\n",
    "    #train_config.num_layers = 1\n",
    "    #test_config.num_layers = 1\n",
    "    test_config.batch_size = 1\n",
    "    test_config.num_steps = 1\n",
    "    loader = data_utils.DataLoader(data=data,batch_size=train_config.batch_size, num_steps=train_config.num_steps)\n",
    "    train_model = model.RNNModel(train_config, True)\n",
    "    test_model = model.RNNModel(test_config, False)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    for idx in range(num_epochs):\n",
    "        epoch_loss = train_model.train_for_epoch(sess, loader)\n",
    "        print(idx, ' ', epoch_loss)\n",
    "        if (idx+1) % 100 == 0:\n",
    "            saver.save(sess, './models/multirnnmodel.ckpt', global_step=idx)\n",
    "    sample_preds = test_model.predict(sess, seq_len=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
